{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS-rEVtBfykZ"
      },
      "source": [
        "# **NN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMxje3bhQ5mU"
      },
      "source": [
        "### **Objetivo:** Implementar **Grid Search** a una arquitectura NN.\n",
        "\n",
        "**Descripción:** Se realiza una búsqueda por Grilla considerando n° de neuronas por capa oculta y cantidad de capas ocultas.\n",
        "\n",
        "**Grilla:**\n",
        "N° de neuronas por capa oculta = [3, 6, 9, 12]\n",
        "N° de capas ocultas = [1, 2, 4, 6, 8]\n",
        "\n",
        "\n",
        "<img src=\"imagenes/reticula.jpg\" alt=\"Retícula generada\" width=\"400\"/>\n",
        "\n",
        "**Variables:**\n",
        "1. componente zonal del viento (u)\n",
        "2. Componente meridional del viento (v)\n",
        "3. temperatura (temp)\n",
        "4. altura geopotencial (alt_geop)\n",
        "\n",
        "**Entrada:** Datos de reanálisis. Corresponde al tiempo *t.*\n",
        "- longitud, latitud, u, v, temperatura y altura geopotencial\n",
        "\n",
        "**Salida:** Inferencias, correspondientes al tiempo *t + 6hs.*\n",
        "- u, v, temperatura y altura geopotencial\n",
        "\n",
        "**Función de pérdida (MSE):**\n",
        "1. Pérdida de datos etiquetados de las variables de salida, comparando el reanálisis y la inferenicia correspondientes a *t + 6 hs.*\n",
        "2. Pérdida de datos etiquetados de las variables de salida, comparando el reanálisis y la inferenicia correspondientes a *t + 12 hs.*\n",
        "\n",
        "**Normalizaciones:**\n",
        "- Variables físicas por media/desvío estándar (M=0, SD=1).\n",
        "- Variables espaciales por mínimo/máximo [0, 1].\n",
        "\n",
        "**Hiperparámetros del modelo:**\n",
        "- Cuatro capas en total, dos ocultas con 6 neuronas cada una.\n",
        "- Función de activación: tangente hiperbólica. Dominio (-inf, inf). Rango (-1, 1).\n",
        "- Learning rate:\n",
        "  - *Cosine learning-rate schedule* de 0,001 a 0,0001\n",
        "- Épocas: 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE-RJ4CVQ5tC",
        "outputId": "703ea0bb-b82b-44a1-94b9-70696451f107"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\"apt-get\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scipy in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.11.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2023.12.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.26.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.2)\n",
            "Requirement already satisfied: pandas in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.1)\n",
            "Requirement already satisfied: openpyxl in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.1.2)\n",
            "Requirement already satisfied: seaborn in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\fabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instala librerías necesarias\n",
        "!apt-get install -y libeccodes-data libeccodes-dev\n",
        "!pip install torch torchvision torchaudio scipy\n",
        "!pip install matplotlib pandas openpyxl seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xSAFYLuuQ6NY"
      },
      "outputs": [],
      "source": [
        "# Importa las librerias necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from netCDF4 import Dataset\n",
        "import os\n",
        "import gc\n",
        "import openpyxl\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¿PyTorch detecta CUDA?: True\n",
            "Versión de CUDA en PyTorch: 12.1\n",
            "GPU detectada: NVIDIA GeForce RTX 3060\n"
          ]
        }
      ],
      "source": [
        "# Definir y verificar el dispositvo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"¿PyTorch detecta CUDA?:\", torch.cuda.is_available())\n",
        "print(\"Versión de CUDA en PyTorch:\", torch.version.cuda)\n",
        "print(\"GPU detectada:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Ninguna\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X2UI8YRTSnYs"
      },
      "outputs": [],
      "source": [
        "# Define las rutas a los archivos\n",
        "\"\"\"\n",
        "1: Geopotential: m**2 s**-2 (instant): isobaricInhPa: level 500: fcst time 0 hrs\n",
        "2: Temperature: K (instant): isobaricInhPa :level 500: fcst time 0 hrs\n",
        "3: U component of wind: m s**-1 (instant): isobaricInhPa: level 500: fcst time 0 hrs\n",
        "4: V component of wind: m s**-1 (instant): isobaricInhPa: level 500: fcst time 0 hrs\n",
        "\n",
        "Continua con 06Z, 12Z y 18Z respestando el orden.\n",
        "\"\"\"\n",
        "ruta_notebook = os.getcwd()\n",
        "ruta_dir_padre = os.path.dirname(ruta_notebook)\n",
        "ruta_files = ruta_dir_padre + '/files/'\n",
        "\n",
        "filename_train = ruta_files + '200401201501.nc'\n",
        "filename_val = ruta_files + '201601.nc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MxuH6GVE4oEg"
      },
      "outputs": [],
      "source": [
        "# Cargar datos desde GRIB\n",
        "def load_nc_data(filename):\n",
        "    # Abre el archivo\n",
        "    ds = Dataset(filename, mode='r')\n",
        "    #print(ds.variables)\n",
        "    \n",
        "    # Selecciona las variables de interés\n",
        "    alt_geop = ds.variables['z'][:].squeeze()        # Altura del geopotencial [m^2*s^-2]\n",
        "    u = ds.variables['u'][:].squeeze()               # Componente zonal del viento [m/s]\n",
        "    v = ds.variables['v'][:].squeeze()               # Componente meridional del viento [m/s]\n",
        "    temp = ds.variables['t'][:].squeeze()            # Temperatura [K]\n",
        "    lat = ds.variables['latitude'][:]                # Latitud [º Norte]\n",
        "    lon = ds.variables['longitude'][:]               # Longitud [º Este]\n",
        "\n",
        "    # Crear la retícula de puntos equiespaciaods\n",
        "    lons, lats = np.meshgrid(lon, lat)\n",
        "\n",
        "    # Extraer los valores para todos los tiempos: (Tiempo, Latitud, Longitud) - Convertir a Array\n",
        "    alt_geop = np.array(alt_geop)\n",
        "    temp = np.array(temp)\n",
        "    u = np.array(u)\n",
        "    v = np.array(v)\n",
        "    lons = np.array(lons)\n",
        "    lats = np.array(lats)\n",
        "\n",
        "    return lons, lats, u, v, temp, alt_geop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "v7mVuvurwQ5t"
      },
      "outputs": [],
      "source": [
        "# Función para normalización Min-Max\n",
        "def min_max_normalize(data):\n",
        "    data_min = np.min(data)\n",
        "    data_max = np.max(data)\n",
        "\n",
        "    if data_max == data_min:\n",
        "        return np.zeros_like(data)  # Evita divisiones por cero en caso de valores constantes\n",
        "\n",
        "    return (data - data_min) / (data_max - data_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ssBuIdNh8IW-"
      },
      "outputs": [],
      "source": [
        "# Función para normalización z-score de datos de entrenamiento\n",
        "def z_score_train_normalize(data):\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "\n",
        "    if std == 0:\n",
        "        return np.zeros_like(data)  # Evita divisiones por cero si los datos son constantes\n",
        "\n",
        "    return mean, std, (data - mean) / std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para normalización z-score\n",
        "def z_score_normalize(data, mean, std):\n",
        "\n",
        "    return (data - mean) / std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YzJAjExel6Zn"
      },
      "outputs": [],
      "source": [
        "class NN(nn.Module):\n",
        "    def __init__(self, hidden_size=6, num_hidden_layers=2):\n",
        "        super(NN, self).__init__()\n",
        "        layers = []\n",
        "\n",
        "        input_size = 6   # x, y, u, v, temp, alt_geop\n",
        "        output_size = 4  # u, v, temp, alt_geop (en t + Δt)\n",
        "\n",
        "        # Capa de entrada\n",
        "        layers.append(nn.Linear(input_size, hidden_size))\n",
        "        layers.append(nn.Tanh())\n",
        "\n",
        "        # Capas ocultas intermedias\n",
        "        for _ in range(num_hidden_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "            layers.append(nn.Tanh())\n",
        "\n",
        "        # Capa de salida\n",
        "        layers.append(nn.Linear(hidden_size, output_size))\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, y, u, v, temp, alt_geop):\n",
        "        inputs = torch.cat([x, y, u, v, temp, alt_geop], dim=1)\n",
        "        output = self.net(inputs)\n",
        "        u_pred, v_pred, temp_pred, alt_geop_pred = output[:, 0:1], output[:, 1:2], output[:, 2:3], output[:, 3:4]\n",
        "        return u_pred, v_pred, temp_pred, alt_geop_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YWmP2DSyn-QW"
      },
      "outputs": [],
      "source": [
        "# Función de pérdida de datos etiquetados (error cuadrático)\n",
        "def label_loss(u_pred, v_pred, temp_pred, alt_geop_pred, u_data, v_data, temp_data, alt_geop_data):\n",
        "\n",
        "    return torch.mean((u_pred - u_data)**2 + (v_pred - v_data)**2 + (temp_pred - temp_data)**2 + (alt_geop_pred - alt_geop_data)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Función para calcular MSE utilizando datos e inferencias\n",
        "def mse_calculated(u_pred, v_pred, temp_pred, alt_geop_pred, u_data, v_data, temp_data, alt_geop_data):\n",
        "\n",
        "    return torch.mean((u_pred - u_data)**2 + (v_pred - v_data)**2 + (temp_pred - temp_data)**2 + (alt_geop_pred - alt_geop_data)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SnnjFFORYjy7"
      },
      "outputs": [],
      "source": [
        "# Cargar datos de entrenamiento\n",
        "\"\"\"\n",
        "Dimensiones:\n",
        "\n",
        "Variables físicas [tiempo, latitud, longitud]: (4*365, 161, 121)\n",
        "Variables espaciales [latitud, longitud]: (161, 121)\n",
        "\"\"\"\n",
        "lons, lats, u_train, v_train, temp_train, alt_geop_train = load_nc_data(filename_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Z_gTxolHEk",
        "outputId": "d2972127-6362-420f-dd3d-e2a3d497180a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de reanálisis para entrenamiento disponibles: 1488\n"
          ]
        }
      ],
      "source": [
        "# Definir la cantidad total de reanálisis horarios\n",
        "dims_train = u_train.shape\n",
        "train_num_reanalysis_hours = dims_train[0]\n",
        "print(f\"Cantidad de reanálisis para entrenamiento disponibles: {train_num_reanalysis_hours}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2JgwE2Tb3cb_"
      },
      "outputs": [],
      "source": [
        "# Cargar datos de validación\n",
        "\"\"\"\n",
        "Dimensiones:\n",
        "\n",
        "Variables físicas [u, v, temperatura, altura geopotencial]: (4*31, 161, 121)\n",
        "Variables espaciales [latitud, longitud]: (161, 121)\n",
        "\"\"\"\n",
        "*_, u_val, v_val, temp_val, alt_geop_val = load_nc_data(filename_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHUPMOPT3ceA",
        "outputId": "d55769bc-64c9-48e8-b6ea-e71cfd7a6df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de reanálisis para validación disponibles: 124\n"
          ]
        }
      ],
      "source": [
        "# Definir la cantidad total de reanálisis horarios\n",
        "dims_val = u_val.shape\n",
        "val_num_reanalysis_hours = dims_val[0]\n",
        "print(f\"Cantidad de reanálisis para validación disponibles: {val_num_reanalysis_hours}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar variables espaciales de entrada\n",
        "lons = min_max_normalize(lons)\n",
        "lats = min_max_normalize(lats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dKJuKg51lHKB"
      },
      "outputs": [],
      "source": [
        "# Tensorizar datos de entrada espacial\n",
        "\"\"\"\n",
        "Dimensiones de los Tensores: torch.Size([19481, 1]), debido a 161 x 121 = 19481\n",
        "\"\"\"\n",
        "lons_tensor = torch.tensor(lons.reshape(-1, 1), dtype=torch.float32)\n",
        "lats_tensor = torch.tensor(lats.reshape(-1, 1), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Mr1h-ZCoq3UY"
      },
      "outputs": [],
      "source": [
        "# Separar los tiempos para armar los tensores de entrenamiento\n",
        "def separate_time(ini, mid, fin, u, v, temp, alt_geop):\n",
        "  \"\"\"\n",
        "  Separa los datos de las variables físicas en el inicio, el tiempo intermedio\n",
        "  que es 06 horas y el tiempo final de 12 horas desde el inicio.\n",
        "  En todos los casos son en retículas de latitud/longitud.\n",
        "  \"\"\"\n",
        "  u_ini, u_mid, u_fin = u[ini, :, :], u[mid, :, :], u[fin, :, :]\n",
        "  v_ini, v_mid, v_fin = v[ini, :, :], v[mid, :, :], v[fin, :, :]\n",
        "  temp_ini, temp_mid, temp_fin = temp[ini, :, :], temp[mid, :, :], temp[fin, :, :]\n",
        "  alt_geop_ini, alt_geop_mid, alt_geop_fin = alt_geop[ini, :, :], alt_geop[mid, :, :], alt_geop[fin, :, :]\n",
        "\n",
        "  return u_ini, v_ini, temp_ini, alt_geop_ini, u_mid, v_mid, temp_mid, alt_geop_mid, u_fin, v_fin, temp_fin, alt_geop_fin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AIWvpZJS6TsE"
      },
      "outputs": [],
      "source": [
        "# Normalizar datos de entrenamiento\n",
        "u_train_mean, u_train_std, u_norm_train = z_score_train_normalize(u_train)\n",
        "v_train_mean, v_train_std, v_norm_train = z_score_train_normalize(v_train)\n",
        "temp_train_mean, temp_train_std, temp_norm_train = z_score_train_normalize(temp_train)\n",
        "alt_geop_train_mean, alt_geop_train_std, alt_geop_norm_train = z_score_train_normalize(alt_geop_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizar datos de validación\n",
        "u_norm_val = z_score_normalize(u_val, u_train_mean, u_train_std)\n",
        "v_norm_val = z_score_normalize(v_val, v_train_mean, v_train_std)\n",
        "temp_norm_val = z_score_normalize(temp_val, temp_train_mean, temp_train_std)\n",
        "alt_geop_norm_val = z_score_normalize(alt_geop_val, alt_geop_train_mean, alt_geop_train_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "noAVH_VPl1Cn"
      },
      "outputs": [],
      "source": [
        "# Tensorizar los datos\n",
        "def tensorize_data(u_ini, v_ini, temp_ini, alt_geop_ini, u_mid, v_mid, temp_mid, alt_geop_mid, u_fin, v_fin, temp_fin, alt_geop_fin):\n",
        "  \"\"\"\n",
        "  Tensorizar los datos de las variables físicas en el inicio, el tiempo intermedio\n",
        "  que es 06 horas y el tiempo final de 12 horas desde el inicio.\n",
        "  \"\"\"\n",
        "  u_tensor_ini = torch.tensor(u_ini.reshape(-1, 1), dtype=torch.float32)\n",
        "  v_tensor_ini = torch.tensor(v_ini.reshape(-1, 1), dtype=torch.float32)\n",
        "  temp_tensor_ini = torch.tensor(temp_ini.reshape(-1, 1), dtype=torch.float32)\n",
        "  alt_geop_tensor_ini = torch.tensor(alt_geop_ini.reshape(-1, 1), dtype=torch.float32)\n",
        "  u_tensor_mid = torch.tensor(u_mid.reshape(-1, 1), dtype=torch.float32)\n",
        "  v_tensor_mid = torch.tensor(v_mid.reshape(-1, 1), dtype=torch.float32)\n",
        "  temp_tensor_mid = torch.tensor(temp_mid.reshape(-1, 1), dtype=torch.float32)\n",
        "  alt_geop_tensor_mid = torch.tensor(alt_geop_mid.reshape(-1, 1), dtype=torch.float32)\n",
        "  u_tensor_fin = torch.tensor(u_fin.reshape(-1, 1), dtype=torch.float32)\n",
        "  v_tensor_fin = torch.tensor(v_fin.reshape(-1, 1), dtype=torch.float32)\n",
        "  temp_tensor_fin = torch.tensor(temp_fin.reshape(-1, 1), dtype=torch.float32)\n",
        "  alt_geop_tensor_fin = torch.tensor(alt_geop_fin.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "  return u_tensor_ini, v_tensor_ini, temp_tensor_ini, alt_geop_tensor_ini, u_tensor_mid, v_tensor_mid, temp_tensor_mid, alt_geop_tensor_mid, u_tensor_fin, v_tensor_fin, temp_tensor_fin, alt_geop_tensor_fin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 3\n",
        "num_hidden_layers = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QLtyUNLDk6Lb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGtUjQGMF_WM",
        "outputId": "de0e45db-7d72-4ab3-a63c-8295d92adc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=3, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=3, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores físicos a la GPU\n",
        "def move_tensors(u_tensor_move, v_tensor_move, temp_tensor_move, alt_geop_tensor_move, dispositivo=device):\n",
        "    u_tensor_move = u_tensor_move.to(dispositivo)\n",
        "    v_tensor_move = v_tensor_move.to(dispositivo)\n",
        "    temp_tensor_move = temp_tensor_move.to(dispositivo)\n",
        "    alt_geop_tensor_move = alt_geop_tensor_move.to(dispositivo)\n",
        "\n",
        "    return u_tensor_move, v_tensor_move, temp_tensor_move, alt_geop_tensor_move"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "92NrRFGCFh44"
      },
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "O7qs7UDrNtqU"
      },
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "epochs = 30\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)\n",
        "\n",
        "# Generar tamaños de conjuntos de entrenamiento\n",
        "partials_train_num_reanalysis_hours =[1488]\n",
        "\n",
        "# Número de rentrenamientos en val\n",
        "num_retrains_val = val_num_reanalysis_hours - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1488]\n"
          ]
        }
      ],
      "source": [
        "print(partials_train_num_reanalysis_hours)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zP1SFkB-l1E_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.78\n",
            "Average Val MSE: 0.77\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [1, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 3\n",
        "num_hidden_layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=3, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=3, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.79\n",
            "Average Val MSE: 0.78\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [1, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 3\n",
        "num_hidden_layers = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=3, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=3, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.79\n",
            "Average Val MSE: 0.79\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [1, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 3\n",
        "num_hidden_layers = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=3, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=3, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 1.10\n",
            "Average Val MSE: 1.04\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [1, 5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 3\n",
        "num_hidden_layers = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=3, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (13): Tanh()\n",
            "    (14): Linear(in_features=3, out_features=3, bias=True)\n",
            "    (15): Tanh()\n",
            "    (16): Linear(in_features=3, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 1.54\n",
            "Average Val MSE: 1.84\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [2, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 6\n",
        "num_hidden_layers = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=6, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.73\n",
            "Average Val MSE: 0.71\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [2, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 6\n",
        "num_hidden_layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=6, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.73\n",
            "Average Val MSE: 0.73\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [2, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 6\n",
        "num_hidden_layers = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=6, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.74\n",
            "Average Val MSE: 0.73\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [2, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 6\n",
        "num_hidden_layers = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=6, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.75\n",
            "Average Val MSE: 0.75\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [2, 5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 6\n",
        "num_hidden_layers = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (13): Tanh()\n",
            "    (14): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (15): Tanh()\n",
            "    (16): Linear(in_features=6, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.78\n",
            "Average Val MSE: 0.78\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [3, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 9\n",
        "num_hidden_layers = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=9, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=9, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.72\n",
            "Average Val MSE: 0.71\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [3, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 9\n",
        "num_hidden_layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=9, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=9, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.71\n",
            "Average Val MSE: 0.70\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [3, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 9\n",
        "num_hidden_layers = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=9, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=9, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.73\n",
            "Average Val MSE: 0.72\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [3, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 9\n",
        "num_hidden_layers = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=9, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=9, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.74\n",
            "Average Val MSE: 0.73\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [3, 5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 9\n",
        "num_hidden_layers = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=9, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (13): Tanh()\n",
            "    (14): Linear(in_features=9, out_features=9, bias=True)\n",
            "    (15): Tanh()\n",
            "    (16): Linear(in_features=9, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.76\n",
            "Average Val MSE: 0.74\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [4, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 12\n",
        "num_hidden_layers = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 225,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=12, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=12, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.71\n",
            "Average Val MSE: 0.71\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [4, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 12\n",
        "num_hidden_layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 217,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=12, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=12, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.71\n",
            "Average Val MSE: 0.70\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [4, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 12\n",
        "num_hidden_layers = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=12, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=12, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.72\n",
            "Average Val MSE: 0.70\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [4, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 12\n",
        "num_hidden_layers = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=12, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=12, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.73\n",
            "Average Val MSE: 0.71\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Punto de grilla [4, 5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parámetros de la Red\n",
        "hidden_size = 12\n",
        "num_hidden_layers = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nhidden_size: cantidad de neuronas de cada capa oculta.\\nnum_hidden_layers: cantidad de capas ocultas.\\n'"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Inicializar modelo\n",
        "model = NN(hidden_size=hidden_size, num_hidden_layers=num_hidden_layers)\n",
        "\"\"\"\n",
        "hidden_size: cantidad de neuronas de cada capa oculta.\n",
        "num_hidden_layers: cantidad de capas ocultas.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover el modelo a la GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=6, out_features=12, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (3): Tanh()\n",
            "    (4): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (5): Tanh()\n",
            "    (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (7): Tanh()\n",
            "    (8): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (9): Tanh()\n",
            "    (10): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (11): Tanh()\n",
            "    (12): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (13): Tanh()\n",
            "    (14): Linear(in_features=12, out_features=12, bias=True)\n",
            "    (15): Tanh()\n",
            "    (16): Linear(in_features=12, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mover los tensores espaciales a la GPU\n",
        "lons_tensor = lons_tensor.to(device)\n",
        "lats_tensor = lats_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar el almacenaje de mse para graficar\n",
        "train_mses_avg = []\n",
        "val_mses_avg = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializar hiperparámetros\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir el scheduler para un Cosine Learning-Rate Schedule\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando entrenamiento con 1488 cantidad de reanálisis.\n",
            "Finalizado entrenamiento con 1488 cantidad de reanálisis.\n",
            "Average Train MSE: 0.76\n",
            "Average Val MSE: 0.75\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de curvas de entrenamiento\n",
        "for partial_train_num_reanalysis_hours in partials_train_num_reanalysis_hours:\n",
        "\n",
        "  # Número de rentrenamientos en train\n",
        "  num_retrains_train = partial_train_num_reanalysis_hours - 2\n",
        "  \n",
        "  print(f\"Iniciando entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Recorrer épocas\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Recorriendo los reanálisis\n",
        "    for retrain in range(num_retrains_train):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Separar tiempos de datos etiquetados\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, usados durante el entrenameinto, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Habilitar la diferenciación automática variables espaciales\n",
        "      lons_tensor.requires_grad_(True)\n",
        "      lats_tensor.requires_grad_(True)\n",
        "      # Habilitar la diferenciación automática variable físicas\n",
        "      u_tensor_ini_train.requires_grad_(True)\n",
        "      v_tensor_ini_train.requires_grad_(True)\n",
        "      temp_tensor_ini_train.requires_grad_(True)\n",
        "      alt_geop_tensor_ini_train.requires_grad_(True)\n",
        "      u_tensor_mid_train.requires_grad_(True)\n",
        "      v_tensor_mid_train.requires_grad_(True)\n",
        "      temp_tensor_mid_train.requires_grad_(True)\n",
        "      alt_geop_tensor_mid_train.requires_grad_(True)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, usados durante el entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12), usados durante el entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de pérdidas datos etiquetados\n",
        "      loss_ini_mid_datos_train = label_loss(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      loss_mid_fin_datos_train = label_loss(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_loss = loss_ini_mid_datos_train + loss_mid_fin_datos_train\n",
        "\n",
        "      # Retropropagación\n",
        "      train_loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "\n",
        "    # Actualizar el learning rate con el scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "  print(f\"Finalizado entrenamiento con {partial_train_num_reanalysis_hours} cantidad de reanálisis.\")\n",
        "\n",
        "  # Evaluar en conjunto de entrenamiento y validación\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Inicializar el primer reanálisis de inicio, intermedio y de fin\n",
        "    ini_train = 0\n",
        "    mid_train = 1\n",
        "    fin_train = 2\n",
        "    ini_val = 0\n",
        "    mid_val = 1\n",
        "    fin_val = 2\n",
        "\n",
        "    # ENTRENAMIENTO\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_train_mse = 0.0\n",
        "\n",
        "    for retrain_train in range(num_retrains_train):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de entrenamiento\n",
        "      u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train = separate_time(ini_train, mid_train, fin_train, u_norm_train, v_norm_train, temp_norm_train, alt_geop_norm_train)\n",
        "      # Tensorizar datos etiquetados de entrenamiento\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = tensorize_data(u_ini_train, v_ini_train, temp_ini_train, alt_geop_ini_train, u_mid_train, v_mid_train, temp_mid_train, alt_geop_mid_train, u_fin_train, v_fin_train, temp_fin_train, alt_geop_fin_train)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de entrenamiento, a device\n",
        "      u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train = move_tensors(u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "      u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train = move_tensors(u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train = move_tensors(u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = model(lons_tensor, lats_tensor, u_tensor_ini_train, v_tensor_ini_train, temp_tensor_ini_train, alt_geop_tensor_ini_train)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de entrenamiento, a device\n",
        "      u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train = move_tensors(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de entrenamiento\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = model(lons_tensor, lats_tensor, u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de entrenamiento, a device\n",
        "      u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train = move_tensors(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de entrenamiento\n",
        "      mse_ini_mid_datos_train = mse_calculated(u_pred_mid_train, v_pred_mid_train, temp_pred_mid_train, alt_geop_pred_mid_train, u_tensor_mid_train, v_tensor_mid_train, temp_tensor_mid_train, alt_geop_tensor_mid_train)\n",
        "      mse_mid_fin_datos_train = mse_calculated(u_pred_fin_train, v_pred_fin_train, temp_pred_fin_train, alt_geop_pred_fin_train, u_tensor_fin_train, v_tensor_fin_train, temp_tensor_fin_train, alt_geop_tensor_fin_train)\n",
        "      train_mse = 0.5*mse_ini_mid_datos_train + 0.5*mse_mid_fin_datos_train\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_train_mse += train_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_train += 1\n",
        "      mid_train += 1\n",
        "      fin_train += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_train_mse = total_train_mse / partial_train_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    train_mses_avg.append(avg_train_mse)\n",
        "\n",
        "    print(f\"Average Train MSE: {avg_train_mse:.2f}\")\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    # Inicializa los mse por tamaño de conjunto de entrenamiento\n",
        "    total_val_mse = 0.0\n",
        "\n",
        "    for retrain_val in range(num_retrains_val):\n",
        "\n",
        "      # Separar tiempos de datos etiquetados de validación\n",
        "      u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val = separate_time(ini_val, mid_val, fin_val, u_norm_val, v_norm_val, temp_norm_val, alt_geop_norm_val)\n",
        "      # Tensorizar datos etiquetados de validación\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = tensorize_data(u_ini_val, v_ini_val, temp_ini_val, alt_geop_ini_val, u_mid_val, v_mid_val, temp_mid_val, alt_geop_mid_val, u_fin_val, v_fin_val, temp_fin_val, alt_geop_fin_val)\n",
        "\n",
        "      # Mover los tensores (t=0) de entrada, de validación, a device\n",
        "      u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val = move_tensors(u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "      u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val = move_tensors(u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val = move_tensors(u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "\n",
        "      # Primera predicción del modelo sobre datos de validación\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = model(lons_tensor, lats_tensor, u_tensor_ini_val, v_tensor_ini_val, temp_tensor_ini_val, alt_geop_tensor_ini_val)\n",
        "\n",
        "      # Mover los tensores (t=6) de entrada, de validación, a device\n",
        "      u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val = move_tensors(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Segunda predicción del modelo sobre datos de validación\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = model(lons_tensor, lats_tensor, u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val)\n",
        "\n",
        "      # Mover los tensores (t=12) de entrada, de validación, a device\n",
        "      u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val = move_tensors(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val)\n",
        "\n",
        "      # Cálculo de mse datos etiquetados de validación\n",
        "      mse_ini_mid_datos_val = mse_calculated(u_pred_mid_val, v_pred_mid_val, temp_pred_mid_val, alt_geop_pred_mid_val, u_tensor_mid_val, v_tensor_mid_val, temp_tensor_mid_val, alt_geop_tensor_mid_val)\n",
        "      mse_mid_fin_datos_val = mse_calculated(u_pred_fin_val, v_pred_fin_val, temp_pred_fin_val, alt_geop_pred_fin_val, u_tensor_fin_val, v_tensor_fin_val, temp_tensor_fin_val, alt_geop_tensor_fin_val)\n",
        "      val_mse = 0.5*mse_ini_mid_datos_val + 0.5*mse_mid_fin_datos_val\n",
        "\n",
        "      # Acumulación de mse por tamaño de conjunto de entrenamiento\n",
        "      total_val_mse += val_mse.item()\n",
        "\n",
        "      # Cambiar los siguientes reanálisis consecutivos\n",
        "      ini_val += 1\n",
        "      mid_val += 1\n",
        "      fin_val += 1\n",
        "  \n",
        "    # Calcular los mse medias\n",
        "    avg_val_mse = total_val_mse / val_num_reanalysis_hours\n",
        "    # Guardar mse para gráficas\n",
        "    val_mses_avg.append(avg_val_mse)\n",
        "\n",
        "    print(f\"Average Val MSE: {avg_val_mse:.2f}\")\n",
        "    print(\"--\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Liberar al dispositivo\n",
        "del model, optimizer, scheduler\n",
        "del train_loss, total_train_mse, train_mse\n",
        "del avg_train_mse, train_mses_avg\n",
        "del total_val_mse, val_mse, avg_val_mse, val_mses_avg\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Armado de Grilla (MSE Validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Armado de los datos de MSE Valdation\n",
        "puntaje_11 = 0.77  # Neuronas=3, Capas=1\n",
        "puntaje_12 = 0.78  # Neuronas=3, Capas=2\n",
        "puntaje_13 = 0.79  # Neuronas=3, Capas=4\n",
        "puntaje_14 = 1.04  # Neuronas=3, Capas=6\n",
        "puntaje_15 = 1.84  # Neuronas=3, Capas=8\n",
        "puntaje_21 = 0.71  # Neuronas=6, Capas=1\n",
        "puntaje_22 = 0.73  # Neuronas=6, Capas=2\n",
        "puntaje_23 = 0.73  # Neuronas=6, Capas=4\n",
        "puntaje_24 = 0.75  # Neuronas=6, Capas=6\n",
        "puntaje_25 = 0.78  # Neuronas=6, Capas=8\n",
        "puntaje_31 = 0.70  # Neuronas=9, Capas=1\n",
        "puntaje_32 = 0.70  # Neuronas=9, Capas=2\n",
        "puntaje_33 = 0.72  # Neuronas=9, Capas=4\n",
        "puntaje_34 = 0.73  # Neuronas=9, Capas=6\n",
        "puntaje_35 = 0.74  # Neuronas=9, Capas=8\n",
        "puntaje_41 = 0.69  # Neuronas=12, Capas=1\n",
        "puntaje_42 = 0.70  # Neuronas=12, Capas=2\n",
        "puntaje_43 = 0.70  # Neuronas=12, Capas=4\n",
        "puntaje_44 = 0.71  # Neuronas=12, Capas=6\n",
        "puntaje_45 = 0.75  # Neuronas=12, Capas=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se arma un nuevo dataframe con los resultados previos\n",
        "data_metrics_v2 = pd.DataFrame([\n",
        "    {'capas': 1, 'neuronas': 3,  'mse': puntaje_11},\n",
        "    {'capas': 2, 'neuronas': 3,  'mse': puntaje_12},\n",
        "    {'capas': 4, 'neuronas': 3,  'mse': puntaje_13},\n",
        "    {'capas': 6, 'neuronas': 3,  'mse': puntaje_14},\n",
        "    {'capas': 8, 'neuronas': 3,  'mse': puntaje_15},\n",
        "    {'capas': 1, 'neuronas': 6,  'mse': puntaje_21},\n",
        "    {'capas': 2, 'neuronas': 6,  'mse': puntaje_22},\n",
        "    {'capas': 4, 'neuronas': 6,  'mse': puntaje_23},\n",
        "    {'capas': 6, 'neuronas': 6,  'mse': puntaje_24},\n",
        "    {'capas': 8, 'neuronas': 6,  'mse': puntaje_25},\n",
        "    {'capas': 1, 'neuronas': 9,  'mse': puntaje_31},\n",
        "    {'capas': 2, 'neuronas': 9,  'mse': puntaje_32},\n",
        "    {'capas': 4, 'neuronas': 9,  'mse': puntaje_33},\n",
        "    {'capas': 6, 'neuronas': 9,  'mse': puntaje_34},\n",
        "    {'capas': 8, 'neuronas': 9,  'mse': puntaje_35},\n",
        "    {'capas': 1, 'neuronas': 12, 'mse': puntaje_41},\n",
        "    {'capas': 2, 'neuronas': 12, 'mse': puntaje_42},\n",
        "    {'capas': 4, 'neuronas': 12, 'mse': puntaje_43},\n",
        "    {'capas': 6, 'neuronas': 12, 'mse': puntaje_44},\n",
        "    {'capas': 8, 'neuronas': 12, 'mse': puntaje_45},\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertimos el DataFrame a una tabla tipo matriz con neuronas en Y y capas en X\n",
        "pivot_table = data_metrics_v2.pivot(index='neuronas', columns='capas', values='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib.colors import Normalize\n",
        "\n",
        "# Crear la figura\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Configurar el colormap y la normalización\n",
        "cmap = plt.get_cmap(\"viridis\")\n",
        "norm = Normalize(vmin=pivot_table.min().min(), vmax=pivot_table.max().max())\n",
        "\n",
        "# Dibujar el mapa de calor\n",
        "ax = sns.heatmap(pivot_table, cmap=cmap, cbar_kws={'label': 'MSE'}, annot=False)\n",
        "\n",
        "# Anotar manualmente con contraste adecuado\n",
        "for y in range(pivot_table.shape[0]):\n",
        "    for x in range(pivot_table.shape[1]):\n",
        "        value = pivot_table.iloc[y, x]\n",
        "        rgba = cmap(norm(value))\n",
        "        brightness = rgba[0]*0.299 + rgba[1]*0.587 + rgba[2]*0.114  # Luma perceptual\n",
        "        text_color = 'black' if brightness > 0.5 else 'white'\n",
        "        ax.text(x + 0.5, y + 0.5, f\"{value:.2f}\",\n",
        "                ha='center', va='center', color=text_color, fontsize=10)\n",
        "\n",
        "# Etiquetas y formato\n",
        "#plt.title(\"Mapa de Calor - MSE Validación - Neuronas vs Capas ocultas\")\n",
        "plt.xlabel(\"Capas\")\n",
        "plt.ylabel(\"Neuronas\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
